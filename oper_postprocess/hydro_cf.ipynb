{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def fixpath(path):\n",
    "    if path.startswith(\"C:\"): return \"/mnt/c/\" + path.replace(\"\\\\\", \"/\")[3:]\n",
    "    else:\n",
    "        pass\n",
    "    return path\n",
    "\n",
    "silver_path = fixpath(r'C:\\SILVER_BC_Cascade\\SILVER_Data\\user_inputs\\Hydro_Data-BC_Cascade')\n",
    "os.chdir(silver_path)\n",
    "\n",
    "# Read the hydro data\n",
    "\n",
    "cascade_pmin_sf = pd.read_csv('hydro_cascade_pmin - saf.csv', index_col=0)\n",
    "cascade_pmin_tk = pd.read_csv('hydro_cascade_pmin - TK.csv', index_col=0)\n",
    "\n",
    "max_cap_cas = pd.read_excel(f'{os.path.dirname(silver_path)}/model inputs - BC_cascade_scen14.xlsx', sheet_name='non-vre plants')\n",
    "max_cap_cas = max_cap_cas.loc[max_cap_cas['name'].str.contains('cascade'), ['name', '[MW]']].transpose()\n",
    "max_cap_cas_h = pd.concat([max_cap_cas]*len(cascade_pmin_sf.index), ignore_index=True)\n",
    "max_cap_cas_h = max_cap_cas_h.loc[pd.to_numeric(max_cap_cas_h.iloc[:,1], errors='coerce').notnull()]\n",
    "max_cap_cas_h.index = cascade_pmin_sf.index\n",
    "max_cap_cas_h.columns = cascade_pmin_sf.columns[0:25]\n",
    "\n",
    "hourly_pmin_sf = pd.read_csv('hydro_hourly_pmin - saf.csv', index_col=0)\n",
    "hourly_pmin_tk = pd.read_csv('hydro_hourly_pmin - TK.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2050-01-01 00:00:00', '2050-01-01 01:00:00',\n",
      "               '2050-01-01 02:00:00', '2050-01-01 03:00:00',\n",
      "               '2050-01-01 04:00:00', '2050-01-01 05:00:00',\n",
      "               '2050-01-01 06:00:00', '2050-01-01 07:00:00',\n",
      "               '2050-01-01 08:00:00', '2050-01-01 09:00:00',\n",
      "               '2050-01-01 10:00:00', '2050-01-01 11:00:00',\n",
      "               '2050-01-01 12:00:00', '2050-01-01 13:00:00',\n",
      "               '2050-01-01 14:00:00', '2050-01-01 15:00:00',\n",
      "               '2050-01-01 16:00:00', '2050-01-01 17:00:00',\n",
      "               '2050-01-01 18:00:00', '2050-01-01 19:00:00',\n",
      "               '2050-01-01 20:00:00', '2050-01-01 21:00:00',\n",
      "               '2050-01-01 22:00:00', '2050-01-01 23:00:00',\n",
      "               '2050-01-02 00:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n"
     ]
    }
   ],
   "source": [
    "# Select the periods of interest\n",
    "\n",
    "periods = input(\"Enter the period of interest in dates (e.g. 2050-01-01 to 2050-03-01): \")\n",
    "periods = periods.split('to')\n",
    "periods = [pd.to_datetime(periods[0]), pd.to_datetime(periods[1])]\n",
    "timeline = pd.date_range(periods[0], periods[1], freq='H')\n",
    "print(timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cascades are available: \n",
      "Index(['cascade_1', 'cascade_2', 'cascade_3', 'cascade_4', 'cascade_5',\n",
      "       'cascade_6', 'cascade_7', 'cascade_8', 'cascade_9', 'cascade_10',\n",
      "       'cascade_11', 'cascade_12', 'cascade_13', 'cascade_14', 'cascade_15',\n",
      "       'cascade_16', 'cascade_17', 'cascade_18', 'cascade_19', 'cascade_20',\n",
      "       'cascade_21', 'cascade_22', 'cascade_23', 'cascade_24', 'cascade_25'],\n",
      "      dtype='object')\n",
      "['cascade_2', 'cascade_4']\n"
     ]
    }
   ],
   "source": [
    "# Selecting the cascades of interest\n",
    "\n",
    "print(\"The following cascades are available: \")\n",
    "print(cascade_cf.columns[1:-3])\n",
    "imp_cascades = input(\"Enter the cascade(s) of interest from the list (e.g. 1,2,3): \")\n",
    "imp_cascades = imp_cascades.split(',')\n",
    "imp_cascades = [int(i) for i in imp_cascades]\n",
    "imp_cascades = [cascade_cf.columns[i] for i in imp_cascades]\n",
    "print(imp_cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the minimum capacity of the cascades\n",
    "\n",
    "imp_factor = input(\"Enter the factor by which the cascading minimum caoacity should be increased (e.g. 1.2): \")\n",
    "imp_factor = float(imp_factor)\n",
    "imp_cascade_pmin = pd.DataFrame(cascade_pmin)\n",
    "imp_cascade_pmin.loc[(cascade_pmin.index >= timeline[0]) & (cascade_pmin.index <= timeline[-1]), imp_cascades] = cascade_pmin.loc[(cascade_pmin.index >= timeline[0]) & (cascade_pmin.index <= timeline[-1]), imp_cascades] * imp_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to new files\n",
    "\n",
    "scen = input(\"Enter the scenario name: \")\n",
    "imp_cascade_pmin.to_csv('hydro_cascade_pmin_' + scen + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rabdnomly producing a range for the hourly minimum capacity\n",
    "\n",
    "from scipy.stats.qmc import LatinHypercube as LH\n",
    "\n",
    "# Create a Latin Hypercube sampler\n",
    "engine = LH(1)\n",
    "\n",
    "cascade_range = 0.55*max_cap_cas_h - cascade_pmin_sf\n",
    "hourly_range = hourly_pmin_tk - hourly_pmin_sf\n",
    "\n",
    "rand_cascade = pd.DataFrame(engine.random(10))\n",
    "rand_cascade.sort_values(by=0, inplace=True)\n",
    "rand_cascade.reset_index(drop=True, inplace=True)\n",
    "rand_hourly = pd.DataFrame(engine.random(10))\n",
    "rand_hourly.sort_values(by=0, inplace=True)\n",
    "rand_hourly.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select random capacities to be sampled\n",
    "rand_cascade_cap = cascade_pmin_sf.sample(n=int(round(len(cascade_pmin_sf.columns)*0.5,0)), axis=1)\n",
    "rand_cascade_cap.dropna(axis=1, inplace=True)\n",
    "rand_hourly_cap = hourly_pmin_sf.sample(n=int(round(len(hourly_pmin_sf.columns)*0.5,0)), axis=1)\n",
    "rand_hourly_cap.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a random sample\n",
    "for i in range(0,10):\n",
    "    locals()[f'cascade_sample_{i}'] = round(rand_cascade.at[i,0] * cascade_range + cascade_pmin_sf,3)\n",
    "    locals()[f'hourly_sample_{i}'] = round(rand_hourly.at[i,0] * hourly_range + hourly_pmin_sf,3)\n",
    "\n",
    "# Write random pmins to csvs\n",
    "for i in range(0,10):\n",
    "    locals()[f'cascade_sample_{i}'].loc[:,rand_cascade_cap.columns] = rand_cascade_cap\n",
    "    locals()[f'cascade_sample_{i}'].to_csv(f'hydro_cascade_pmin_{i}.csv')\n",
    "    locals()[f'hourly_sample_{i}'].loc[:,rand_hourly_cap.columns] = rand_hourly_cap\n",
    "    locals()[f'hourly_sample_{i}'].to_csv(f'hydro_hourly_pmin_{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d8f24f45ef014f5fb6768b31535b4dd99303d4856b951d6e9db5276c5b96092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
